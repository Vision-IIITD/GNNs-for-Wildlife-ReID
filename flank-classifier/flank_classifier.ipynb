{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import wandb\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 20,\n",
    "    \"num_classes\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2g1b2npc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">baseline</strong> at: <a href='https://wandb.ai/atharv_goel/tiger-flank-classifier/runs/2g1b2npc' target=\"_blank\">https://wandb.ai/atharv_goel/tiger-flank-classifier/runs/2g1b2npc</a><br/> View project at: <a href='https://wandb.ai/atharv_goel/tiger-flank-classifier' target=\"_blank\">https://wandb.ai/atharv_goel/tiger-flank-classifier</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240803_081630-2g1b2npc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2g1b2npc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/atharv21027/ReID-with-graphs/wandb/run-20240803_081801-rvkspnmk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/atharv_goel/tiger-flank-classifier/runs/rvkspnmk' target=\"_blank\">baseline</a></strong> to <a href='https://wandb.ai/atharv_goel/tiger-flank-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/atharv_goel/tiger-flank-classifier' target=\"_blank\">https://wandb.ai/atharv_goel/tiger-flank-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/atharv_goel/tiger-flank-classifier/runs/rvkspnmk' target=\"_blank\">https://wandb.ai/atharv_goel/tiger-flank-classifier/runs/rvkspnmk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"tiger-flank-classifier\", name=\"baseline\")\n",
    "config = wandb.config\n",
    "config.update(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='/mnt/nas/WII-flanks/train_images', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root='/mnt/nas/WII-flanks/val_images', transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root='/mnt/nas/WII-flanks/test_images', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2038 267 360\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/wildlife10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/wildlife10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 59.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, config.num_classes)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:05<20:38, 65.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1866, Validation Accuracy: 94.01%\n",
      "Epoch [2/20], Loss: 0.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:38<13:50, 46.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2167, Validation Accuracy: 89.51%\n",
      "Epoch [3/20], Loss: 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:08<11:06, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1456, Validation Accuracy: 94.01%\n",
      "Epoch [4/20], Loss: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:41<09:45, 36.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1170, Validation Accuracy: 95.13%\n",
      "Epoch [5/20], Loss: 0.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [03:12<08:40, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1372, Validation Accuracy: 94.38%\n",
      "Epoch [6/20], Loss: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:42<07:41, 32.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5804, Validation Accuracy: 77.90%\n",
      "Epoch [7/20], Loss: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:11<06:53, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0865, Validation Accuracy: 96.63%\n",
      "Epoch [8/20], Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [04:41<06:12, 31.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1397, Validation Accuracy: 96.63%\n",
      "Epoch [9/20], Loss: 0.0578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [05:12<05:40, 30.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1404, Validation Accuracy: 96.25%\n",
      "Epoch [10/20], Loss: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [05:44<05:12, 31.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1792, Validation Accuracy: 91.76%\n",
      "Epoch [11/20], Loss: 0.0667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [06:16<04:44, 31.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0785, Validation Accuracy: 96.25%\n",
      "Epoch [12/20], Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [06:49<04:15, 31.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1233, Validation Accuracy: 96.63%\n",
      "Epoch [13/20], Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [07:21<03:45, 32.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1755, Validation Accuracy: 95.88%\n",
      "Epoch [14/20], Loss: 0.0313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [07:56<03:16, 32.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1167, Validation Accuracy: 95.88%\n",
      "Epoch [15/20], Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [08:29<02:45, 33.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1669, Validation Accuracy: 95.13%\n",
      "Epoch [16/20], Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [09:03<02:12, 33.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1276, Validation Accuracy: 97.00%\n",
      "Epoch [17/20], Loss: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [09:36<01:39, 33.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0935, Validation Accuracy: 97.75%\n",
      "Epoch [18/20], Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [10:08<01:05, 32.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1171, Validation Accuracy: 96.25%\n",
      "Epoch [19/20], Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [10:41<00:33, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1151, Validation Accuracy: 95.88%\n",
      "Epoch [20/20], Loss: 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [11:14<00:00, 33.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1284, Validation Accuracy: 96.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.tqdm(range(config.num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{config.num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    # Log training loss to wandb\n",
    "    wandb.log({\"Training Loss\": epoch_loss, \"epoch\": epoch + 1})\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Log validation loss and accuracy to wandb\n",
    "    wandb.log({\"Validation Loss\": val_loss, \"Validation Accuracy\": val_accuracy, \"epoch\": epoch + 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = 'tiger_flank_classifier.pt'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "wandb.save(model_path)\n",
    "\n",
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1343, Test Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Compute test accuracy\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Tuple\n",
    "\n",
    "\n",
    "class FlankDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.class_to_idx = {'left': 0, 'right': 1}\n",
    "        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     image, label = super().__getitem__(idx)\n",
    "\n",
    "    #     # get the path of the image\n",
    "    #     image_path, _ = self.samples[idx]\n",
    "    #     return image, self.idx_to_class[label], image_path\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (sample, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3730 4000\n"
     ]
    }
   ],
   "source": [
    "inference_train_set = FlankDataset(root='datasets/WII/wii.coco/image_by_identity/train', transform=transform)\n",
    "inference_train_loader = DataLoader(inference_train_set, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "inference_test_set = FlankDataset(root='datasets/WII/wii.coco/image_by_identity/test', transform=transform)\n",
    "inference_test_loader = DataLoader(inference_test_set, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "print(len(inference_train_set), len(inference_test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': 0, 'right': 1}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_train_set.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_map = {}\n",
    "test_map = {}\n",
    "\n",
    "# get the first item in the dataloadre\n",
    "labels[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the labels on the infernce sets and save them\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, identities, img_paths in inference_train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "        # check if labels is in map\n",
    "        for i, (flank_label, identity, path) in enumerate(zip(predicted.cpu().numpy(), identities, img_paths)):\n",
    "            identity = int(inference_train_set.classes[identity.item()])\n",
    "            # get the image name\n",
    "            image_name = os.path.basename(path)\n",
    "    \n",
    "            if identity not in train_map:\n",
    "                train_map[identity] = {\"left_flank\": [], \"right_flank\": []}\n",
    "\n",
    "            if int(flank_label) == 0:\n",
    "                train_map[identity][\"left_flank\"].append(image_name)\n",
    "            elif int(flank_label) == 1:\n",
    "                train_map[identity][\"right_flank\"].append(image_name)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, identities, img_paths in inference_test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # check if labels is in map\n",
    "        for i, (flank_label, identity, path) in enumerate(zip(predicted.cpu().numpy(), identities, img_paths)):\n",
    "            identity = int(inference_test_set.classes[identity.item()])\n",
    "            # get the image name\n",
    "            image_name = os.path.basename(path)\n",
    "    \n",
    "            if identity not in test_map:\n",
    "                test_map[identity] = {\"left_flank\": [], \"right_flank\": []}\n",
    "\n",
    "            if int(flank_label) == 0:\n",
    "                test_map[identity][\"left_flank\"].append(image_name)\n",
    "            elif int(flank_label) == 1:\n",
    "                test_map[identity][\"right_flank\"].append(image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 191)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_map), len(test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only those items that have both left and right flanks in the training set\n",
    "train_map_filter = {k: v for k, v in train_map.items() if len(v[\"left_flank\"]) > 5 and len(v[\"right_flank\"]) > 5}\n",
    "test_map_filter = {k: v for k, v in test_map.items() if len(v[\"left_flank\"]) > 5 and len(v[\"right_flank\"]) > 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 78)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_map_filter), len(test_map_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each item, choose 5 random images from each flank for gallery and the remaining for probe\n",
    "import random\n",
    "\n",
    "def split_flanks(map_filter):\n",
    "    random.seed(42)\n",
    "\n",
    "    gallery = {}\n",
    "    query = {}\n",
    "\n",
    "    for identity, flanks in map_filter.items():\n",
    "        left_flank = flanks[\"left_flank\"]\n",
    "        right_flank = flanks[\"right_flank\"]\n",
    "\n",
    "        random.shuffle(left_flank)\n",
    "        random.shuffle(right_flank)\n",
    "\n",
    "        k_left = 6 if len(left_flank) > 6 else 5\n",
    "        k_right = 6 if len(right_flank) > 6 else 5\n",
    "\n",
    "        gallery[identity] = {\n",
    "            \"left_flank\": left_flank[:k_left],\n",
    "            \"right_flank\": right_flank[:k_right]\n",
    "        }\n",
    "\n",
    "        query[identity] = {\n",
    "            \"left_flank\": left_flank[k_left:],\n",
    "            \"right_flank\": right_flank[k_right:]\n",
    "        }\n",
    "\n",
    "    return gallery, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gallery, train_query = split_flanks(train_map_filter)\n",
    "test_gallery, test_query = split_flanks(test_map_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(gallery, query):\n",
    "    final_json = []\n",
    "    for (identity, flanks), (identity_query, flanks_query) in zip(gallery.items(), query.items()):\n",
    "        assert identity == identity_query\n",
    "        final_json.append({\n",
    "            \"tiger_id\": identity,\n",
    "            \"gallery\": {\n",
    "                \"left_flank\": flanks[\"left_flank\"],\n",
    "                \"right_flank\": flanks[\"right_flank\"]\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"left_flank\": flanks_query[\"left_flank\"],\n",
    "                \"right_flank\": flanks_query[\"right_flank\"]\n",
    "            }\n",
    "        })\n",
    "\n",
    "    return final_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_json = get_json(train_gallery, train_query)\n",
    "final_test_json = get_json(test_gallery, test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json \n",
    "with open('datasets/WII/wii.coco/gallery_metadata_train.json', 'w') as f:\n",
    "    json.dump(final_train_json, f, indent=4)\n",
    "\n",
    "with open('datasets/WII/wii.coco/gallery_metadata_test.json', 'w') as f:\n",
    "    json.dump(final_test_json, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
